{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd14cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Dataset loaded with 4999 rows and 12 columns.\n",
      "Removing duplicate rows based on 'ID' column...\n",
      "Dataset after removing duplicates: 4999 rows.\n",
      "Cleaning 'Runtime' column...\n",
      "Normalizing numerical columns: 'Rating', 'Votes', and 'Gross'...\n",
      "Cleaning and preprocessing the 'Plot' column for text analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\guled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\guled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed for 'Plot'.\n",
      "Saving the preprocessed dataset...\n",
      "Preprocessed data saved to: ./Preprocessed_Movies_IMDb.csv\n",
      "Displaying a sample of the preprocessed dataset:\n",
      "   ID                           Movie Name    Rating  Runtime  \\\n",
      "0   1             The Shawshank Redemption  1.000000    142.0   \n",
      "1   2                        The Godfather  0.973684    175.0   \n",
      "2   3  Ramayana: The Legend of Prince Rama  0.973684    135.0   \n",
      "3   4                      The Chaos Class  0.973684     87.0   \n",
      "4   5                                Daman  0.947368    121.0   \n",
      "\n",
      "                          Genre  Metascore  \\\n",
      "0                         Drama       82.0   \n",
      "1                  Crime, Drama      100.0   \n",
      "2  Animation, Action, Adventure        NaN   \n",
      "3                 Comedy, Drama        NaN   \n",
      "4              Adventure, Drama        NaN   \n",
      "\n",
      "                                                Plot  \\\n",
      "0  Over the course of several years, two convicts...   \n",
      "1  Don Vito Corleone, head of a mafia family, dec...   \n",
      "2  An anime adaptation of the Hindu epic the Rama...   \n",
      "3  Lazy, uneducated students share a very close b...   \n",
      "4  The film is set in 2015. Sid, is a young docto...   \n",
      "\n",
      "                                           Directors  \\\n",
      "0  ['Frank Darabont', 'Tim Robbins', 'Morgan Free...   \n",
      "1  ['Francis Ford Coppola', 'Marlon Brando', 'Al ...   \n",
      "2  ['Ram Mohan', 'Yûgô Sakô', 'Koichi Saski', 'Ar...   \n",
      "3  ['Ertem Egilmez', 'Kemal Sunal', 'Münir Özkul'...   \n",
      "4  ['Lenka Debiprasad', 'Vishal Mourya', 'Karan K...   \n",
      "\n",
      "                                               Stars     Votes     Gross  \\\n",
      "0  ['Tim Robbins', 'Morgan Freeman', 'Bob Gunton'...  1.000000  0.030258   \n",
      "1  ['Marlon Brando', 'Al Pacino', 'James Caan', '...  0.694551  0.144093   \n",
      "2  ['Yûgô Sakô', 'Koichi Saski', 'Arun Govil', 'N...  0.000037  0.000011   \n",
      "3  ['Kemal Sunal', 'Münir Özkul', 'Halit Akçatepe...  0.011588  0.000045   \n",
      "4  ['Vishal Mourya', 'Karan Kandhapan', 'Babushan...  0.001202  0.000014   \n",
      "\n",
      "                                     Link  \\\n",
      "0   https://www.imdb.com/title/tt0111161/   \n",
      "1   https://www.imdb.com/title/tt0068646/   \n",
      "2   https://www.imdb.com/title/tt0259534/   \n",
      "3   https://www.imdb.com/title/tt0252487/   \n",
      "4  https://www.imdb.com/title/tt17592606/   \n",
      "\n",
      "                                        Cleaned_Plot  \n",
      "0  course several year two convict form friendshi...  \n",
      "1  vito corleone head mafia family decides hand e...  \n",
      "2  anime adaptation hindu epic ramayana lord ram ...  \n",
      "3  lazy uneducated student share close bond live ...  \n",
      "4  film set sid young doctor completed mbbs poste...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load dataset\n",
    "file_path = './Top_5000_Movies_IMDb.csv'\n",
    "print(\"Loading the dataset...\")\n",
    "data = pd.read_csv(file_path)\n",
    "print(f\"Dataset loaded with {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
    "\n",
    "# Remove duplicates based on 'ID' column\n",
    "print(\"Removing duplicate rows based on 'ID' column...\")\n",
    "data = data.drop_duplicates(subset=['ID'])\n",
    "print(f\"Dataset after removing duplicates: {data.shape[0]} rows.\")\n",
    "\n",
    "# Extract runtime in minutes and clean it\n",
    "print(\"Cleaning 'Runtime' column...\")\n",
    "data['Runtime'] = data['Runtime'].str.replace(' min', '', regex=False).astype(float, errors='ignore')\n",
    "\n",
    "# Normalize numerical columns\n",
    "print(\"Normalizing numerical columns: 'Rating', 'Votes', and 'Gross'...\")\n",
    "numerical_cols = ['Rating', 'Votes', 'Gross']\n",
    "scaler = MinMaxScaler()\n",
    "data[numerical_cols] = data[numerical_cols].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "\n",
    "# Preprocess the 'Plot' column for text analysis\n",
    "print(\"Cleaning and preprocessing the 'Plot' column for text analysis...\")\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        # Remove stopwords and non-alphabetic tokens\n",
    "        filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "        # Lemmatize tokens\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "        return \" \".join(lemmatized_tokens)\n",
    "    return \"\"\n",
    "\n",
    "data['Cleaned_Plot'] = data['Plot'].apply(preprocess_text)\n",
    "print(\"Text preprocessing completed for 'Plot'.\")\n",
    "\n",
    "# Save the final preprocessed data\n",
    "final_file_path = './Preprocessed_Movies_IMDb.csv'\n",
    "print(\"Saving the preprocessed dataset...\")\n",
    "data.to_csv(final_file_path, index=False)\n",
    "print(f\"Preprocessed data saved to: {final_file_path}\")\n",
    "\n",
    "# Print a sample of the cleaned dataset\n",
    "print(\"Displaying a sample of the preprocessed dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01c95db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Dataset loaded successfully with 8560 rows and 8 columns.\n",
      "Columns in the dataset: ['Unnamed: 0', 'id', 'title', 'overview', 'release_date', 'popularity', 'vote_average', 'vote_count']\n",
      "Removing duplicate rows based on 'id' column...\n",
      "Dataset after removing duplicates: 8559 rows.\n",
      "Converting 'release_date' to datetime...\n",
      "Normalizing numerical columns: 'popularity', 'vote_average', 'vote_count'...\n",
      "Cleaning and preprocessing the 'overview' column for text analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\guled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\guled\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed for 'overview'.\n",
      "Saving the preprocessed dataset...\n",
      "Preprocessed data saved to: C:\\Users\\guled\\movie_recommender\\final_preprocessed_movie.csv\n",
      "Verifying the preprocessed dataset...\n",
      "Final dataset contains 8559 rows and 9 columns.\n",
      "Columns in the final dataset: ['Unnamed: 0', 'id', 'title', 'overview', 'release_date', 'popularity', 'vote_average', 'vote_count', 'cleaned_overview']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5e6f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_preprocessed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert release_date to datetime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m final_preprocessed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(final_preprocessed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Optional: Verify the change\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_preprocessed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_preprocessed_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d295cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
